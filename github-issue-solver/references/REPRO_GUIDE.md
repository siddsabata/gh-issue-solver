# Reproduction Harness Guide

## Purpose

A reproduction harness proves the bug exists and confirms when it's fixed. It must be:
- **Deterministic**: Same result every run
- **Self-contained**: Runs from repo root with no manual setup
- **Binary**: Exit 0 = fixed, Exit 1 = bug present

## Immutability Rule

**Once the repro script is created and confirms the bug (exits 1), do not edit it.**

The repro is the source of truth. If verification fails:
- Fix the source code, not the test
- The repro defines what "fixed" means

**When to ask the user before modifying repro:**
- Repro doesn't actually reproduce the reported bug
- Repro tests the wrong behavior
- Repro has a fundamental logic error

If you believe the repro is wrong, stop and ask the user:
> "The repro script may not accurately capture the bug because [reason]. Should I modify it to [proposed change]?"

## Directory Structure

```
.claude/gh-issue-solver/issues/<issue_num>/repro/
├── repro.py           # Python reproduction logic
├── repro.sh           # Shell wrapper
├── README.md          # Instructions for maintainers
└── fixtures/          # Any test data needed
    └── ...
```

## repro.py Template

```python
#!/usr/bin/env python3
"""
Reproduction script for GitHub Issue #<NUM>
Generated by github-issue-solver skill

Exit codes:
  0 = Bug is FIXED (test passes)
  1 = Bug is PRESENT (test fails)
"""
import sys


def main() -> int:
    """
    Reproduce the bug and return appropriate exit code.

    Returns:
        0 if bug is fixed, 1 if bug is present
    """
    try:
        # === Setup ===
        # Minimal setup required to trigger the bug

        # === Execute ===
        # Call the buggy code path
        # result = some_function()

        # === Assert ===
        # Check if bug is present or fixed
        # expected = "correct_value"
        # if result != expected:
        #     print(f"FAIL: Expected {expected!r}, got {result!r}")
        #     return 1

        print("PASS: Bug appears to be fixed")
        return 0

    except Exception as e:
        # Unexpected exception = bug is present
        print(f"FAIL: {type(e).__name__}: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
```

## repro.sh Template

```bash
#!/usr/bin/env bash
set -euo pipefail

# ============================================================
# Reproduction wrapper for GitHub Issue #<NUM>
# Generated by github-issue-solver skill
# ============================================================

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
REPO_ROOT="$(cd "$SCRIPT_DIR/../../.." && pwd)"

cd "$REPO_ROOT"

echo "=== Environment ==="
echo "OS: $(uname -s) $(uname -r)"
echo "Python: $(python3 --version)"
echo "uv: $(uv --version)"
echo "PWD: $(pwd)"
echo "==================="
echo

# Install dependencies if needed
uv sync --quiet

# Run the reproduction
echo "Running reproduction..."
uv run python "$SCRIPT_DIR/repro.py"
EXIT_CODE=$?

echo
if [ $EXIT_CODE -eq 0 ]; then
    echo "=== PASS: Bug appears to be fixed ==="
else
    echo "=== FAIL: Bug is still present ==="
fi

exit $EXIT_CODE
```

## README.md Template

```markdown
# Reproduction for Issue #<NUM>

## Quick Start

From repo root:
\`\`\`bash
bash .claude/gh-issue-solver/issues/<issue_num>/repro/repro.sh
\`\`\`

Or run Python directly:
\`\`\`bash
uv run python .claude/gh-issue-solver/issues/<issue_num>/repro/repro.py
\`\`\`

## Expected Results

- **FAIL (exit 1)**: Bug is present - [describe what happens]
- **PASS (exit 0)**: Bug is fixed - [describe expected behavior]

## What This Tests

[Brief description of the bug and what the repro validates]

## Dependencies

- Python 3.x
- uv package manager
- [any other requirements]
```

## Writing Good Reproductions

### Minimize

Remove everything not needed to trigger the bug:
- Use smallest possible input
- Remove unrelated imports
- Simplify configuration

### Isolate

Avoid dependencies on:
- External services (mock if needed)
- Specific file paths (use temp dirs)
- Timing-dependent behavior
- Random values (seed if needed)

### Assert Clearly

```python
# Bad: Silent failure
result = buggy_function()

# Good: Clear assertion with context
result = buggy_function()
expected = "correct_value"
if result != expected:
    print(f"FAIL: Expected {expected!r}, got {result!r}")
    return 1
print("PASS: Function returned expected value")
return 0
```

### Handle Exceptions

For bugs where exceptions should NOT be raised:

```python
def main() -> int:
    try:
        result = function_that_should_not_raise()
        print("PASS: No exception raised")
        return 0
    except SpecificError as e:
        print(f"FAIL: Raised {type(e).__name__}: {e}")
        return 1
```

For bugs where exceptions SHOULD be raised:

```python
def main() -> int:
    try:
        function_that_should_raise()
        print("FAIL: Expected exception was not raised")
        return 1
    except ExpectedError:
        print("PASS: Correct exception raised")
        return 0
```

## Common Patterns

### Testing import behavior

```python
def main() -> int:
    try:
        from package.module import function
        print("PASS: Import successful")
        return 0
    except ImportError as e:
        print(f"FAIL: Import failed: {e}")
        return 1
```

### Testing with fixtures

```python
import json
from pathlib import Path

def main() -> int:
    fixture_path = Path(__file__).parent / "fixtures" / "test_input.json"
    with open(fixture_path) as f:
        data = json.load(f)

    # ... test logic using data ...
    return 0
```

### Testing CLI behavior

```python
import subprocess
import sys

def main() -> int:
    result = subprocess.run(
        [sys.executable, "-m", "package.cli", "--flag"],
        capture_output=True,
        text=True
    )

    if "expected pattern" in result.stdout:
        print("PASS: Output contains expected pattern")
        return 0
    else:
        print(f"FAIL: Output did not contain expected pattern")
        print(f"Got: {result.stdout}")
        return 1
```

## Iteration

If initial repro fails to capture the bug:

1. Re-read the issue for missed details
2. Check environment differences
3. Try exact code from issue reporter
4. Ask user for clarification after 2 failed attempts

Update repro.py and re-run until it reliably shows:
- FAIL before fix is applied
- PASS after fix is applied
